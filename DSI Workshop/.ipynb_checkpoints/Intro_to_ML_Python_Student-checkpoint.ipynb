{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning with Python\n",
    "\n",
    "Now that we've learned how to acquire, clean, and visualize our data, let's start doing some machine learning. Throughout this workshop, we will be using a Python package called scikit-learn. It is surprisingly easy to implement machine learning algorithms using scikit-learn, and in fact much of the work is done for you. Often, it is the acquisition and structuring of the data itself that requires the most finesse. Because of this, we will be working with pre-processed data to illustrate just how simple machine learning can be using scikit-learn. \n",
    "\n",
    "Before we dive in, let's start with some background on machine learning. There are two main types of machine learning algorithms: **supervised** and **unsupervised**. The goal of **supervised learning** is to train a model to classify data against a set of labels. For instance, we can train a model to separate images according to whether or not the image contains a face. In this case, the two labels would be *face* and *no face*. The presence of labeled training data is a huge advantage in machine learning, however it is not always available.\n",
    "\n",
    "When labeled training data is unavailable, we must use **unsupervised learning**. The goal of unsupervised learning is to train a model to extract *meaningful features* from the data. These meaningful features are often common patterns which are useful for compressing the information contained in the data. For example, in speech recognition, individual phonemes serve as meaningful features from which it is possible to reconstruct words independently of their tone or pitch. In computer vision, oriented edge-detectors are often the best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Digit Recognition\n",
    "\n",
    "In the first half of this workshop, we'll be using a very important supervised machine learning algorithm called the **support vector machine** to classify handwritten digits. This is a very well-studied problem in the machine learning community, and serves as a great starting point. First, let's import scikit-learn and a couple other modules we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sklearn comes with a few preloaded datasets, so let's load up the handwritten digits dataset. This is a list of pixel intensities corresponding to images of handwritten digits plus their associated labels (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "print (digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib to see what one of these images looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACxNJREFUeJzt3fuLXPUZx/HPp5vErRqTYqxKNjShaEAqNZqmhIjQBEus\nokJL3YCWSmGhoCiGihZL239A0h+KIFErmBpsVBDrBVsVK6QxF1M1txKDJRvURLwHTLLm6Q87gShp\n92zmnO+ZeXy/YHEvw36fQd45Z2ZnztcRIQA5fa3tAQA0h8CBxAgcSIzAgcQIHEiMwIHECBxIjMCB\nxAgcSGxKE790mk+JQZ3WxK9u1dissvfpnHPeL7bWvoMzi601OHqk2FpxZKzYWiV9poM6HIc80e0a\nCXxQp+n7XtbEr27Vez9eXHS9X61cW2yt32y+ptha59/2drG1xt55t9haJW2Iv1e6HafoQGIEDiRG\n4EBiBA4kRuBAYgQOJEbgQGIEDiRWKXDby23vsr3b9h1NDwWgHhMGbntA0h8lXSHpAkkrbF/Q9GAA\nulflCL5I0u6I2BMRhyWtlVTudY0ATlqVwGdL2nvc16Od7wHocbW92cT2iKQRSRrUqXX9WgBdqHIE\n3ydpznFfD3W+9wURcW9ELIyIhVN1Sl3zAehClcA3SjrP9jzb0yQNS3qi2bEA1GHCU/SIGLN9k6Rn\nJQ1Iuj8itjU+GYCuVXoMHhFPSXqq4VkA1IxXsgGJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQWCM7\nm2RVcqcRSRqe/kGxtVbN/LTYWn/d8myxtS753S+LrSVJs+5dX3S9iXAEBxIjcCAxAgcSI3AgMQIH\nEiNwIDECBxIjcCAxAgcSq7Kzyf2299t+o8RAAOpT5Qj+J0nLG54DQAMmDDwiXpL0foFZANSMx+BA\nYmxdBCRW2xGcrYuA3sMpOpBYlT+TPSxpvaT5tkdt/6L5sQDUocreZCtKDAKgfpyiA4kROJAYgQOJ\nETiQGIEDiRE4kBiBA4kROJBY329dNLb0kmJrDU/fWmwtSbpi+XCxtWa8trPYWj99eVmxtd5f8Hmx\ntSRpVtHVJsYRHEiMwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxKpcdHGO7Rdsb7e9zfYt\nJQYD0L0qr0Ufk7QyIrbYni5ps+3nImJ7w7MB6FKVvcnejogtnc8/kbRD0uymBwPQvUm9m8z2XEkL\nJG04wc/YugjoMZWfZLN9uqRHJd0aER9/+edsXQT0nkqB256q8bjXRMRjzY4EoC5VnkW3pPsk7YiI\nu5sfCUBdqhzBl0i6QdJS21s7Hz9qeC4ANaiyN9nLklxgFgA145VsQGIEDiRG4EBiBA4kRuBAYgQO\nJEbgQGIEDiTW93uTfXZmubtw1/4Li60lSUcL7hdW0sbXv932CF8ZHMGBxAgcSIzAgcQIHEiMwIHE\nCBxIjMCBxAgcSIzAgcSqXHRx0PYrtv/V2bro9yUGA9C9Kq/zPCRpaUR82rl88su2n46IfzY8G4Au\nVbnoYkj6tPPl1M5HNDkUgHpU3fhgwPZWSfslPRcRJ9y6yPYm25uO6FDdcwI4CZUCj4jPI+IiSUOS\nFtn+zgluw9ZFQI+Z1LPoEfGhpBckLW9mHAB1qvIs+lm2Z3Y+/7qkyyXlfKMykEyVZ9HPlfSg7QGN\n/4PwSEQ82exYAOpQ5Vn01zS+JziAPsMr2YDECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIrP+3LvpG\nuX+j1qxfXGwtSTpfrxRdr5QpMw4XW2vso2nF1upFHMGBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgc\nSIzAgcQqB965NvqrtrkeG9AnJnMEv0XSjqYGAVC/qjubDEm6UtLqZscBUKeqR/BVkm6XdLTBWQDU\nrMrGB1dJ2h8Rmye4HXuTAT2myhF8iaSrbb8laa2kpbYf+vKN2JsM6D0TBh4Rd0bEUETMlTQs6fmI\nuL7xyQB0jb+DA4lN6oouEfGipBcbmQRA7TiCA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJBY329d\nNPhBuTe4fe/CN4utJUkfFVxryjlnF1vrugv+7/uWavXI05cWW6sXcQQHEiNwIDECBxIjcCAxAgcS\nI3AgMQIHEiNwIDECBxKr9Eq2zhVVP5H0uaSxiFjY5FAA6jGZl6r+ICLea2wSALXjFB1IrGrgIelv\ntjfbHmlyIAD1qXqKfmlE7LP9TUnP2d4ZES8df4NO+COSNKhTax4TwMmodASPiH2d/+6X9LikRSe4\nDVsXAT2myuaDp9mefuxzST+U9EbTgwHoXpVT9LMlPW772O3/HBHPNDoVgFpMGHhE7JH03QKzAKgZ\nfyYDEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwILG+37rojF3lNvj57dCTxdaSpJ+N3FZsranXHii2\nVknz7lzf9git4ggOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRWKXDbM22vs73T9g7bi5se\nDED3qr5U9Q+SnomIn9ieJnHhc6AfTBi47RmSLpP0c0mKiMOSDjc7FoA6VDlFnyfpgKQHbL9qe3Xn\n+ugAelyVwKdIuljSPRGxQNJBSXd8+Ua2R2xvsr3piA7VPCaAk1El8FFJoxGxofP1Oo0H/wVsXQT0\nngkDj4h3JO21Pb/zrWWStjc6FYBaVH0W/WZJazrPoO+RdGNzIwGoS6XAI2KrpIUNzwKgZrySDUiM\nwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIrO/3Jjv62s5ia113z8pia0nSXSsfLrbWqjeXFVtr\n40UDxdb6quMIDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kNmHgtufb3nrcx8e2by0xHIDu\nTPhS1YjYJekiSbI9IGmfpMcbngtADSZ7ir5M0psR8Z8mhgFQr8m+2WRY0gnfAWF7RNKIJA2y+SjQ\nEyofwTubHlwt6S8n+jlbFwG9ZzKn6FdI2hIR7zY1DIB6TSbwFfofp+cAelOlwDv7gV8u6bFmxwFQ\np6p7kx2UdGbDswCoGa9kAxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxR0T9v9Q+IGmybymdJem9\n2ofpDVnvG/erPd+KiLMmulEjgZ8M25siYmHbczQh633jfvU+TtGBxAgcSKyXAr+37QEalPW+cb96\nXM88BgdQv146ggOoWU8Ebnu57V22d9u+o+156mB7ju0XbG+3vc32LW3PVCfbA7Zftf1k27PUyfZM\n2+ts77S9w/bitmfqRuun6J1rrf9b41eMGZW0UdKKiNje6mBdsn2upHMjYovt6ZI2S7q23+/XMbZv\nk7RQ0hkRcVXb89TF9oOS/hERqzsXGj01Ij5se66T1QtH8EWSdkfEnog4LGmtpGtanqlrEfF2RGzp\nfP6JpB2SZrc7VT1sD0m6UtLqtmepk+0Zki6TdJ8kRcThfo5b6o3AZ0vae9zXo0oSwjG250paIGlD\nu5PUZpWk2yUdbXuQms2TdEDSA52HH6s71yPsW70QeGq2T5f0qKRbI+Ljtufplu2rJO2PiM1tz9KA\nKZIulnRPRCyQdFBSXz8n1AuB75M057ivhzrf63u2p2o87jURkeWKtEskXW37LY0/nFpq+6F2R6rN\nqKTRiDh2prVO48H3rV4IfKOk82zP6zypMSzpiZZn6ppta/yx3I6IuLvteeoSEXdGxFBEzNX4/6vn\nI+L6lseqRUS8I2mv7fmdby2T1NdPik52b7LaRcSY7ZskPStpQNL9EbGt5bHqsETSDZJet721871f\nR8RTLc6Eid0saU3nYLNH0o0tz9OV1v9MBqA5vXCKDqAhBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4k\n9l+8Q5/pEyhkXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e821ff7c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEruQnAHP/g0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e822cd9eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, matplotlib plots each value on a color scale. We can convert this to greyscale to get a better idea of the actual image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e822e0d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[0], cmap = plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a better idea of what our data looks like, let's begin organizing it. An important concept in machine learning is overfitting. Overfitting typically occurs when a model has a large number of parameters, but not much data. An overfit model will perform very well on its training data, but will be unable to generalize beyond this training data.\n",
    "\n",
    "To prevent overfitting, we will split our dataset into two groups: training data and test data. This will allow us to evaluate how our model performs on data it's never seen before. This procedure is called cross-validation and is extremely important in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(digits.data,\n",
    "                                                                   digits.target,\n",
    "                                                                   test_size = .3,\n",
    "                                                                   random_state = 42) #random state is like seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 1, ..., 2, 7, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video describing SVM: https://www.youtube.com/watch?v=mA5nwGoRAOo\n",
    "\n",
    "From here, creating and training our classifier is relatively straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma = 0.001, C = 100)\n",
    "clf.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the accuracty of our classifier using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907407407407407"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = clf.score(data_test, labels_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video describing C: https://www.youtube.com/watch?v=joTa_FeMZ2s\n",
    "\n",
    "Video describing gamma: https://www.youtube.com/watch?v=m2a2K4lprQw\n",
    "\n",
    "That's pretty impressive. So what are those mysterious values gamma and C? The C parameter controls the penalty for misclassification of each example in the training data. Large values of C highly penalize misclassification, and thus will fit to the training data more exactly. However, this can lead to overfitting and trouble with outliers, in which case a smaller value of C should be chosen.\n",
    "\n",
    "The gamma parameter is somewhat more complicated, but it can be understood to be the radius of influence of the individual support vectors. More info can be found in the sklearn SVM documentation: http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "\n",
    "So let's try changing the values of C and gamma and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09259259259259259"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma = 0.1, C = 100)\n",
    "clf.fit(data_train, labels_train)\n",
    "accuracy = clf.score(data_test, labels_test)\n",
    "accuracy #becomes 9% which is bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can automate the process of finding the best values of gamma and C (also known as hyperparameters) by using sklearn's built in grid-search function. Note that a new classifier must be built, trained, and evaluated for each combination of hyperparameters, so this process can be time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = {\"C\": [1,10,100], \"gamma\":[.1,.01,.001]}\n",
    "gridsearch = GridSearchCV(svm.SVC(), param_grid)\n",
    "gridsearch.fit(data_test, labels_test)\n",
    "print(gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle: Making a Submission\n",
    "\n",
    "Kaggle is an excellent platform for participating in data science competitions, accessing cool datasets, and getting involved in the data science community. For part two of this workshop, we will be using Kaggle's Biological Response competition data to create a Kaggle submission entry. This is part of Kaggle's Getting Started with Python tutorial, which can be found here: https://www.kaggle.com/wiki/GettingStartedWithPythonForDataScience\n",
    "\n",
    "First let's check out the dataset, which can be found here: https://www.kaggle.com/c/bioresponse/data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...        0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...        1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...        0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...        0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...        0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"BioResponseTrain.csv\") # biological response to molecular indicator???\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in this dataframe represents a specific molecule, and the column labeled \"Activity\" denotes whether the molecule elicits a specific biological response, (1), or not, (0). The descriptors D1, D2, ..., D1773 quantitatively describe relevant structural and chemical properties of the molecule. The goal is to use these descriptors as features and predict the activity of new molecules.\n",
    "\n",
    "First, let's split our data into training and test cases. Since the first column represents our labels, or target values, we must be sure to separate them from our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "5       0\n",
       "6       1\n",
       "7       1\n",
       "8       1\n",
       "9       0\n",
       "10      1\n",
       "11      0\n",
       "12      1\n",
       "13      1\n",
       "14      1\n",
       "15      1\n",
       "16      1\n",
       "17      1\n",
       "18      1\n",
       "19      0\n",
       "20      0\n",
       "21      1\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      1\n",
       "26      1\n",
       "27      0\n",
       "28      1\n",
       "29      1\n",
       "       ..\n",
       "3721    1\n",
       "3722    1\n",
       "3723    0\n",
       "3724    1\n",
       "3725    1\n",
       "3726    0\n",
       "3727    0\n",
       "3728    1\n",
       "3729    0\n",
       "3730    1\n",
       "3731    0\n",
       "3732    1\n",
       "3733    0\n",
       "3734    1\n",
       "3735    1\n",
       "3736    0\n",
       "3737    0\n",
       "3738    0\n",
       "3739    1\n",
       "3740    1\n",
       "3741    0\n",
       "3742    0\n",
       "3743    0\n",
       "3744    0\n",
       "3745    1\n",
       "3746    1\n",
       "3747    1\n",
       "3748    0\n",
       "3749    1\n",
       "3750    0\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = data[\"Activity\"]\n",
    "features = data.iloc[:,1:]\n",
    "\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features, targets, test_size = .3, random_state = 42)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.076266</td>\n",
       "      <td>0.591766</td>\n",
       "      <td>0.068019</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.210929</td>\n",
       "      <td>0.685980</td>\n",
       "      <td>0.275813</td>\n",
       "      <td>0.455651</td>\n",
       "      <td>0.749446</td>\n",
       "      <td>0.271110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025143</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.022476</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.009905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.105676</td>\n",
       "      <td>0.077284</td>\n",
       "      <td>0.117272</td>\n",
       "      <td>0.102230</td>\n",
       "      <td>0.078774</td>\n",
       "      <td>0.089809</td>\n",
       "      <td>0.161590</td>\n",
       "      <td>0.071969</td>\n",
       "      <td>0.096940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156589</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.122522</td>\n",
       "      <td>0.148254</td>\n",
       "      <td>0.122522</td>\n",
       "      <td>0.129828</td>\n",
       "      <td>0.108049</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.140678</td>\n",
       "      <td>0.099047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.137873</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.275590</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.515541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137208</td>\n",
       "      <td>0.625657</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>0.379767</td>\n",
       "      <td>0.707378</td>\n",
       "      <td>0.196318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.585755</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190488</td>\n",
       "      <td>0.673729</td>\n",
       "      <td>0.278383</td>\n",
       "      <td>0.499343</td>\n",
       "      <td>0.738210</td>\n",
       "      <td>0.284976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.667152</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258611</td>\n",
       "      <td>0.739747</td>\n",
       "      <td>0.336056</td>\n",
       "      <td>0.571095</td>\n",
       "      <td>0.787935</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.960920</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932451</td>\n",
       "      <td>0.957093</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                D1           D2           D3           D4           D5  \\\n",
       "count  2625.000000  2625.000000  2625.000000  2625.000000  2625.000000   \n",
       "mean      0.076266     0.591766     0.068019     0.039524     0.210929   \n",
       "std       0.076994     0.105676     0.077284     0.117272     0.102230   \n",
       "min       0.000000     0.282128     0.000000     0.000000     0.002630   \n",
       "25%       0.033300     0.515541     0.000000     0.000000     0.137208   \n",
       "50%       0.066700     0.585755     0.050000     0.000000     0.190488   \n",
       "75%       0.100000     0.667152     0.100000     0.000000     0.258611   \n",
       "max       0.766667     0.960920     0.650000     1.000000     0.932451   \n",
       "\n",
       "                D6           D7           D8           D9          D10  \\\n",
       "count  2625.000000  2625.000000  2625.000000  2625.000000  2625.000000   \n",
       "mean      0.685980     0.275813     0.455651     0.749446     0.271110   \n",
       "std       0.078774     0.089809     0.161590     0.071969     0.096940   \n",
       "min       0.137873     0.071600     0.067800     0.275590     0.003040   \n",
       "25%       0.625657     0.208889     0.379767     0.707378     0.196318   \n",
       "50%       0.673729     0.278383     0.499343     0.738210     0.284976   \n",
       "75%       0.739747     0.336056     0.571095     0.787935     0.344084   \n",
       "max       0.957093     0.790831     0.989870     1.000000     1.000000   \n",
       "\n",
       "          ...             D1767        D1768        D1769        D1770  \\\n",
       "count     ...       2625.000000  2625.000000  2625.000000  2625.000000   \n",
       "mean      ...          0.025143     0.014857     0.015238     0.022476   \n",
       "std       ...          0.156589     0.121004     0.122522     0.148254   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1771        D1772        D1773        D1774        D1775  \\\n",
       "count  2625.000000  2625.000000  2625.000000  2625.000000  2625.000000   \n",
       "mean      0.015238     0.017143     0.011810     0.011048     0.020190   \n",
       "std       0.122522     0.129828     0.108049     0.104545     0.140678   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1776  \n",
       "count  2625.000000  \n",
       "mean      0.009905  \n",
       "std       0.099047  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 1776 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be using a random forest classifier. The random forest classifier can be thought of as an ensemble of individual decision tree classifiers. These decision tree classifiers are trained to extract the most relevant features and make a series of decisions based on given input using these features. While decision trees are prone to overfitting by themselves, as part of an ensemble they form a robust model.\n",
    "\n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/f/f3/CART_tree_titanic_survivors.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf.fit(features_train, targets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this decision tree classifier to make some predictions on our test data, and see how it holds up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8001776198934281\n"
     ]
    }
   ],
   "source": [
    "accuracy = rf.score(features_test, targets_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's an intro to Machine learning in Python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
