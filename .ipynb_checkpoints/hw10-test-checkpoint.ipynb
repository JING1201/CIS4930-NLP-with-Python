{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "all_tagged_nouns = [(w.lower(), tag) for (w, tag) in brown.tagged_words() if \n",
    "             (tag.startswith('NN') or tag.startswith('NNS') or tag.startswith('NP') or tag.startswith('NPS')) \n",
    "            and not (tag.startswith('NN$') or tag.startswith('NP$') or tag.startswith('NPS$') or tag.startswith('NNS$'))]\n",
    "all_nouns = [w for (w, tag) in all_tagged_nouns]\n",
    "noun_set = set(all_nouns)\n",
    "# getting only singular and plural common and proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fq_nouns = nltk.FreqDist(all_nouns)\n",
    "inf = inflect.engine() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = 0\n",
    "for w in list(noun_set):\n",
    "    if inf.singular_noun(w) is False: #if noun is singular (because it cannot be converted to plural)\n",
    "        plural_w = inf.plural_noun(w)\n",
    "        if fq_nouns[plural_w] > fq_nouns[w]:\n",
    "            ans += 1\n",
    "        #print (w, plural_w)\n",
    "    else:\n",
    "        singular_w = inf.singular_noun(w)\n",
    "        if fq_nouns[singular_w] < fq_nouns[w]:\n",
    "            ans += 1\n",
    "        #print (singular_w, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5017"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# question b\n",
    "tagged = [(w.lower(), tag) for (w, tag) in brown.tagged_words() if w.isalpha()]\n",
    "tagged_words = {}\n",
    "for (w, tag) in tagged:\n",
    "    if w not in tagged_words.keys():\n",
    "        tagged_words[w] = [tag]\n",
    "    else:\n",
    "        if tag not in tagged_words[w]:\n",
    "            tagged_words[w].append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_word = []\n",
    "max_tags = 0\n",
    "for w in tagged_words.keys():\n",
    "    if len(tagged_words[w]) > max_tags:\n",
    "        max_tags = len(tagged_words[w])\n",
    "        max_word = [w]\n",
    "    elif len(tagged_words[w]) == max_tags:\n",
    "        max_word.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tags are:  ['CS', 'WPS', 'DT', 'QL', 'WPO', 'CS-HL', 'DT-TL', 'WPS-TL', 'DT-HL', 'DT-NC', 'NIL', 'WPS-NC', 'WPO-NC', 'CS-NC', 'WPS-HL']\n"
     ]
    }
   ],
   "source": [
    "print ('The tags are: ', tagged_words[max_word[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = [tag for (w, tag) in brown.tagged_words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fq_tags = nltk.FreqDist(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 152470),\n",
       " ('IN', 120557),\n",
       " ('AT', 97959),\n",
       " ('JJ', 64028),\n",
       " ('.', 60638),\n",
       " (',', 58156),\n",
       " ('NNS', 55110),\n",
       " ('CC', 37718),\n",
       " ('RB', 36464),\n",
       " ('NP', 34476),\n",
       " ('VB', 33693),\n",
       " ('VBN', 29186),\n",
       " ('VBD', 26167),\n",
       " ('CS', 22143),\n",
       " ('PPS', 18253),\n",
       " ('VBG', 17893),\n",
       " ('PP$', 16872),\n",
       " ('TO', 14918),\n",
       " ('PPSS', 13802),\n",
       " ('CD', 13510)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fq_tags.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backward_tags = list(reversed(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (0, len(backward_tags)):\n",
    "    if (backward_tags[i].startswith('NN') or tag.startswith('NNS') or tag.startswith('NP') or tag.startswith('NPS')):\n",
    "        backward_tags[i] = 'NOUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backward_fq = nltk.ConditionalFreqDist(list(nltk.bigrams(backward_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AT', 59656),\n",
       " ('JJ', 40864),\n",
       " ('IN', 24012),\n",
       " ('NOUN', 23702),\n",
       " ('PP$', 12241),\n",
       " ('CC', 6610),\n",
       " ('CD', 5264),\n",
       " ('AP', 5112),\n",
       " ('DT', 4540),\n",
       " ('VBG', 4407),\n",
       " (',', 3973),\n",
       " ('VBN', 3638),\n",
       " ('.', 3160),\n",
       " ('JJ-TL', 2595),\n",
       " ('VB', 2432),\n",
       " ('NP', 2013),\n",
       " ('NP-TL', 1877),\n",
       " ('CS', 1745),\n",
       " ('NP$', 1654),\n",
       " ('DTI', 1557)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_fq['NOUN'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "                 for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = [word for word in list(all_words)[:2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        boolean = False\n",
    "        synsets = wn.synsets(word)\n",
    "        if len(synsets) == 0:\n",
    "            features['contains({})'.format(word)] = (word in document_words)\n",
    "        else:\n",
    "            for synset in synsets:\n",
    "                for lemma in synset.lemma_names():\n",
    "                    if lemma in document_words:\n",
    "                        boolean = True\n",
    "                        break\n",
    "                if boolean == True:\n",
    "                    break\n",
    "            features['contains({})'.format(word)] = (boolean)\n",
    "    '''\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    '''\n",
    "    return features\n",
    "#accuracy1: 0.8, 0.84, 0.75\n",
    "#accuracy2: 0.8, 0.79, 0.81, 0.82, 0.83, 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "     contains(atrocious) = True              neg : pos    =     11.8 : 1.0\n",
      "        contains(turkey) = True              neg : pos    =      8.8 : 1.0\n",
      " contains(unimaginative) = True              neg : pos    =      7.7 : 1.0\n",
      "        contains(shoddy) = True              neg : pos    =      7.1 : 1.0\n",
      "    contains(schumacher) = True              neg : pos    =      6.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
